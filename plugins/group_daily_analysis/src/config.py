import json
from pathlib import Path
from typing import Optional, List, Any
from pydantic import BaseModel, Field
from nonebot.log import logger

class LLMConfig(BaseModel):
    # openai_compatible: /chat/completions (OpenAI 兼容接口，保持现状)
    # google_ai_studio: Gemini Developer API (AI Studio 官方接口 generateContent)
    provider: str = "openai_compatible"

    # OpenAI compatible config
    api_key: str
    base_url: str = "https://api.openai.com/v1"

    # Google AI Studio config (optional)
    # 为空时回退使用 api_key
    google_api_key: Optional[str] = None
    google_base_url: str = "https://generativelanguage.googleapis.com/v1beta"

    model: str = "gpt-3.5-turbo"
    timeout: float = 60.0
    proxy: Optional[str] = None

class PluginConfig(BaseModel):
    llm: LLMConfig
    max_concurrent_tasks: int = 3
    max_messages: int = 0  # 设为 0 表示不限制最大消息数，依靠 LLM 长窗口和自适应算法处理
    analysis_days: int = 1
    auto_analysis_time: str = "09:00"
    enable_auto_analysis: bool = False
    bot_qq_ids: List[str] = []
    enable_user_card: bool = False
    report_template: str = "scrapbook"
    min_messages_threshold: int = 50
    watermark_text: str = "Generated by HakuBot · Refactored by Hakuchumu"
    
    # Analysis toggles
    topic_analysis_enabled: bool = True
    user_title_analysis_enabled: bool = True
    golden_quote_analysis_enabled: bool = True
    
    # Analysis limits
    max_topics: int = 5
    max_user_titles: int = 8
    max_golden_quotes: int = 5
    
    # Map-Reduce Settings
    max_input_length: int = 30000  # 字符数阈值，超过则分块 (建议调大以发挥现代长窗口模型优势)
    
    # Prompts
    topic_analysis_prompt: str
    topic_merge_prompt: str = (
        "你是群聊总结助手。以下是分段分析得到的群聊话题列表，请将它们**合并、去重**，并输出全天最重要的 "
        "**{max_topics}** 个话题。\n\n"
        "## 待合并话题：\n{topics_text}\n\n"
        "---\n\n"
        "## 重要：必须返回标准 JSON 格式（只允许输出 JSON，不要任何解释/前后缀/markdown）\n"
        "严格遵守：\n"
        "1. 只输出一个 JSON 数组，数组元素为对象\n"
        "2. 字段必须为：topic（字符串）, contributors（字符串数组）, detail（字符串）\n"
        "3. 不要输出 markdown 代码块标记（```）\n"
        "4. 不要在 JSON 外添加任何文字说明\n\n"
        "## 合并规则：\n"
        "1. 合并相似话题（同义、同事件、同人物同主题都算相似）\n"
        "2. contributors 合并去重，最多保留 5 人\n"
        "3. detail 保留信息量最大、最具体的一条，并可适当融合关键信息\n\n"
        "### 返回格式示例：\n"
        "[\n"
        "  {\n"
        "    \"topic\": \"话题名称\",\n"
        "    \"contributors\": [\"用户1\", \"用户2\"],\n"
        "    \"detail\": \"具体描述（包含关键信息和结论）\"\n"
        "  }\n"
        "]\n\n"
        "**注意**：请以纯正的 JSON 数组格式返回，绝不能包含 markdown 代码块标记(即前后不要有 ```json 和 ```)。"
    )
    
    user_title_analysis_prompt: str
    
    golden_quote_analysis_prompt: str
    golden_quote_merge_prompt: str = (
        "你是毒舌、幽默、热衷网络冲浪的乐子人。以下是分段分析选出的候选金句，请从中进行 PK，"
        "决选出最逆天的 **{max_golden_quotes}** 句。\n\n"
        "## 候选金句：\n{quotes_text}\n\n"
        "---\n\n"
        "## 重要：必须返回标准 JSON 格式（只允许输出 JSON，不要任何解释/前后缀/markdown）\n"
        "严格遵守：\n"
        "1. 只输出一个 JSON 数组\n"
        "2. 字段必须为：content（字符串）, sender（字符串）, reason（字符串）\n"
        "3. 不要输出 markdown 代码块标记（```）\n"
        "4. 不要在 JSON 外添加任何文字说明\n\n"
        "## 规则：\n"
        "1. 严格按“逆天指数”从高到低排序\n"
        "2. 去除重复或高度相似的句子（语义相同也算重复）\n"
        "3. reason 要像群友吐槽，拒绝 AI 腔，短而狠\n\n"
        "### 返回格式示例：\n"
        "[\n"
        "  {\n"
        "    \"content\": \"金句原文\",\n"
        "    \"sender\": \"发言人昵称\",\n"
        "    \"reason\": \"你的毒舌辣评\"\n"
        "  }\n"
        "]\n\n"
        "**注意**：请以纯正的 JSON 数组格式返回，绝不能包含 markdown 代码块标记(即前后不要有 ```json 和 ```)。"
    )

CONFIG_PATH = Path(__file__).parent.parent / "config.json"

def load_config() -> PluginConfig:
    if not CONFIG_PATH.exists():
        raise FileNotFoundError(f"Config file not found: {CONFIG_PATH}")
    
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    # Try to load ai_assistant config if API key is placeholder
    if data["llm"]["api_key"] == "YOUR_API_KEY":
        try:
            ai_config_path = Path(__file__).parent.parent.parent / "ai_assistant" / "config.json"
            if ai_config_path.exists():
                with open(ai_config_path, "r", encoding="utf-8") as f:
                    ai_data = json.load(f)
                    data["llm"]["api_key"] = ai_data.get("api_key", "")
                    data["llm"]["base_url"] = ai_data.get("base_url", data["llm"]["base_url"])
                    data["llm"]["model"] = ai_data.get("chat_model", data["llm"]["model"])
                    data["llm"]["proxy"] = ai_data.get("proxy", data["llm"]["proxy"])

                    # Sync provider switch + google fields (optional)
                    if "provider" in ai_data:
                        data["llm"]["provider"] = ai_data.get("provider", data["llm"].get("provider", "openai_compatible"))
                    if "google_api_key" in ai_data:
                        data["llm"]["google_api_key"] = ai_data.get("google_api_key", data["llm"].get("google_api_key"))
                    if "google_base_url" in ai_data:
                        data["llm"]["google_base_url"] = ai_data.get("google_base_url", data["llm"].get("google_base_url"))

                    logger.info("已从 ai_assistant 插件加载 LLM 配置")
            else:
                logger.warning("未找到 ai_assistant 配置文件，请手动配置 LLM API")
        except Exception as e:
            logger.warning(f"加载 ai_assistant 配置失败: {e}，请手动配置 LLM API")

    return PluginConfig(**data)

def save_config(config: PluginConfig):
    with open(CONFIG_PATH, "w", encoding="utf-8") as f:
        json.dump(config.dict(), f, indent=4, ensure_ascii=False)

plugin_config = load_config()
